\newpage

\section{Partie 1: Quelques opérations de base sur les signaux}

\subsection{Signal numérique de synthèse}

\subsubsection{Génération du signal}

Un signal sinusoïdal de fréquence \( f_0 \) est généré par la fonction suivante:

\[
x[n] = \sin\left(2\pi f_0 \frac{n}{f_e}\right)
\]

où \( f_e \) est la fréquence d’échantillonnage et \( N \) le nombre d’échantillons.

\begin{figure}[!h]
\centering
\includegraphics[width=17cm]{screenshots/signal_echantillone.png}
\caption{Signal sinusoïdal échantillonné}
\end{figure}

\subsubsection{Énergie et puissance}

L'énergie d’un signal discret \( x[n] \) est donnée par :

\[
E = \sum_{n=0}^{N-1} x[n]^2
\]

Et la puissance moyenne par :

\[
P = \frac{1}{N} \sum_{n=0}^{N-1} x[n]^2
\]

Considérons un signal sinusoïdal discret de la forme :
\[
x[n] = A \cdot \sin\left(2\pi f_0 \frac{n}{f_e} \right)
\]

La puissance moyenne théorique d’un signal périodique est calculée par la  formule:

\[
P = \lim_{N \to \infty} \frac{1}{N} \sum_{n=0}^{N-1} x[n]^2
\]

En utilisant l’identité trigonométrique :
\[
\sin^2(\theta) = \frac{1 - \cos(2\theta)}{2}
\]
on obtient :
\[
x[n]^2 = A^2 \cdot \frac{1 - \cos\left(4\pi f_0 \frac{n}{f_e} \right)}{2}
\]

Ainsi, la puissance devient :
\[
P = \lim_{N \to \infty} \frac{1}{N} \sum_{n=0}^{N-1} A^2 \cdot \frac{1 - \cos\left(4\pi f_0 \frac{n}{f_e} \right)}{2}
= \lim_{N \to \infty}  \frac{A^2}{2} - \frac{A^2}{2N} \sum_{n=0}^{N-1} \cos\left(4\pi f_0 \frac{n}{f_e} \right)
= \frac{A^2}{2}
\] 

Donc dans notre cas la puissance moyenne théorique est égale à 0.5.

Pour la puissance moyenne calculée numériquement pour le signal échantillonné on a la méme formule mais sans la limite:

\[
P = \frac{A^2}{2} - \frac{A^2}{2N} \sum_{n=0}^{N-1} \cos\left(4\pi f_0 \frac{n}{f_e} \right)
\] 

\textbf{Cas idéal :} si $N$ est un multiple entier de la période du signal (i.e., $N$ couvre un nombre entier de périodes), alors la somme des cosinus s’annule :
\[
\sum_{n=0}^{N-1} \cos\left(4\pi f_0 t \right) = 0 \quad \Rightarrow \quad P = \frac{A^2}{2}
\]

\textbf{Cas général :} si $N$ n’est pas un multiple exact de la période, la somme ne s’annule pas et on observe une légère déviation de la puissance par rapport à $\frac{A^2}{2}$. Cela est dû au fait que le signal est tronqué entre deux points non symétriques.\\

En variant N on trouve plusieurs valeurs de la puissance moyenne qui restent proches de la valeur théorique:

\begin{figure}[!h]
\centering
\includegraphics[width=15cm]{screenshots/puissance_et_energie.png}
\caption{Énergie et puissance du signal}
\end{figure}

\subsubsection{Quantification}

\begin{figure}[!h]
\centering
\includegraphics[width=15.5cm]{screenshots/quantification_graph.png}
\caption{Quantification du signal à 3 et 8 bits}
\end{figure}

Pour la quantification à 3 bits, on retrouve bien 8 niveaux de quantification.

\begin{figure}[!h]
\centering
\includegraphics[width=17cm]{screenshots/quantification_graph_zoomed.png}
\caption{Zoom sur la quantification du signal à 3 et 8 bits}
\end{figure}

Le signal à 8 bits suit mieux la forme continue du signal d’origine mais on voit quand méme quelques erruers. À 3 bits, les marches sont plus visibles et le signal produit est significativement moins fidéle au signal d'origine.\\

\textbf{SNR (Signal-to-Noise Ratio)} :

\[
\text{SNR} = 10 \log_{10} \left(\frac{E_{\text{signal}}}{E_{\text{bruit}}} \right)
\]

\begin{figure}[!h]
\centering
\includegraphics{screenshots/snr_quantification.png}
\caption{SNR pour chaque niveau de quantification}
\end{figure}

On remarque que l'energie du bruit est plus élevée pour le signal quantifié à 3 bits. Le résultat est logique
car on voit sur le graphe que ce signal est plus éloigné du signal d'origine comparé au signal quantifié à 8 bits.
On a la méme conclusion en raisonant sur le SNR: SNRq8 > SNRq3.

\subsection{Signal audio}

\subsubsection{Enregistrement}

Les mots « Bonjour » et « ChatGpt » ont été enregistrés via Audacity (voir figure \ref{fig:signal_enregistre}).

\subsubsection{Restitution à différentes fréquences}

L’audio est lu à \( f_e \), \( 2 f_e \) et \( \frac{f_e}{2} \). 

\textbf{Effets observés} :

\begin{itemize}
    \item \textbf{Durée :} doubler la fréquence de restitution divise la durée par deux (voix accélérée), tandis que la diviser par deux double la durée (voix ralentie).
    \item \textbf{Hauteur :} multiplier la fréquence de restitution rend la voix plus aiguë (fréquences doublées), la diminuer la rend plus grave (fréquences divisées).
\end{itemize}

Lorsque la fréquence de restitution est trop grande ou trop petite comparée à la fréquence d’échantillonnage, le son devient incompréhensible. Le son est trop rapide ou trop lent, mais aussi on ne reconnaît plus les mots. Cela s'explique notamment par le déplacement des formants, c’est-à-dire des pics de résonance caractéristiques des voyelles et consonnes, qui changent de position dans le spectre. Leur modification rend la parole méconnaissable, car ce sont eux qui permettent d’identifier les sons du langage.

\subsubsection{Quantification du signal audio}

\begin{itemize}
    \item À 3 bits : le son devient rugueux et très bruité, fortement altéré.
    \item À 8 bits : la voix reste compréhensible mais moins naturelle.
\end{itemize}

\subsubsection{Extraction et séparation de mots}

Après repérage visuel, les deux mots ont été extraits via tranches temporelles.


\begin{figure}[!h]
\centering
\includegraphics[width=10cm]{screenshots/signal_enregistré.png}
\caption{Signal audio enregistré}
\label{fig:signal_enregistre}
\end{figure}

\begin{figure}[h]
\centering
\begin{subfigure}[b]{0.45\textwidth}
    \centering
    \includegraphics[width=9cm]{screenshots/mot1_graphe.png}
    \caption{Mot 1: "Bonjour"}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.45\textwidth}
    \centering
    \includegraphics[width=9cm]{screenshots/mot2_graphe.png}
    \caption{Mot 2: "ChatGpt"}
\end{subfigure}
\caption{Séparation des mots dans le signal audio}
\end{figure}
